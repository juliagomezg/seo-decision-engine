# ============================================
# SEO DECISION ENGINE - ENVIRONMENT VARIABLES
# ============================================
# Copy this file to .env.local and fill in your actual values
# NEVER commit .env.local to version control
# ============================================

# ============================================
# SUPABASE CONFIGURATION (Required)
# ============================================
# Get these from: https://supabase.com/dashboard/project/_/settings/api

# Public key (safe to expose in frontend)
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key-here

# Service role key (NEVER expose to frontend, server-side only)
# This key bypasses Row Level Security - use carefully
SUPABASE_SERVICE_KEY=your-service-role-key-here

# ============================================
# LLM API KEYS (Required)
# ============================================

# OpenAI API Key (for intent analysis & template proposal)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Claude API Key (alternative to OpenAI for reasoning)
# Get from: https://console.anthropic.com/settings/keys
CLAUDE_API_KEY=sk-ant-...

# Groq API Key (for fast content generation)
# Get from: https://console.groq.com/keys
GROQ_API_KEY=gsk...

# ============================================
# LLM CONFIGURATION (Optional)
# ============================================

# Which LLM to use for intent analysis
# Options: openai | claude
LLM_REASONING_PROVIDER=openai

# Model for reasoning tasks (intent analysis, template proposal)
# OpenAI options: gpt-4-turbo-preview | gpt-4 | gpt-3.5-turbo
# Claude options: claude-3-opus-20240229 | claude-3-sonnet-20240229
LLM_REASONING_MODEL=gpt-4-turbo-preview

# Model for content generation (via Groq)
# Options: mixtral-8x7b-32768 | llama2-70b-4096
LLM_GENERATION_MODEL=mixtral-8x7b-32768

# ============================================
# N8N WEBHOOKS (Optional - Day 2)
# ============================================
# If using n8n for orchestration, add webhook URLs here
# Leave empty to use direct LLM calls

# Intent analysis webhook
N8N_INTENT_WEBHOOK_URL=

# Template proposal webhook
N8N_TEMPLATE_WEBHOOK_URL=

# Content generation webhook
N8N_GENERATION_WEBHOOK_URL=

# ============================================
# PROMPT VERSIONING (Required)
# ============================================

# Current prompt version (semantic versioning)
PROMPT_VERSION=v1.0.0

# ============================================
# APPLICATION CONFIGURATION (Optional)
# ============================================

# Default user name for demo mode
DEFAULT_USER_NAME=demo

# Maximum retries for LLM calls if validation fails
MAX_LLM_RETRIES=2

# Request timeout in milliseconds
LLM_REQUEST_TIMEOUT=30000

# ============================================
# DEVELOPMENT MODE (Optional)
# ============================================

# Enable verbose logging
DEBUG_MODE=false

# Use mock responses instead of real LLM calls (for testing)
USE_MOCK_RESPONSES=false

# ============================================
# NOTES
# ============================================
# - All API keys should be kept secure
# - Service role key grants full database access - handle with care
# - In production, use environment-specific variables
# - Prompt version should be updated when prompts change
# - LLM providers can be swapped by changing REASONING_PROVIDER
